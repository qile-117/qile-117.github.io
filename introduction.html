<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Introduction</title>
    <style>
        /* 基础样式 */
        body {
            margin: 0;
            padding: 20px;
            background: url('introduction.jpg') no-repeat center center fixed;
            background-size: cover;
            font-family: 'Tahoma', Arial, sans-serif;
            min-height: 100vh;
            overflow-x: hidden;
            display: flex;
            justify-content: center;
        }

        /* 文字内容容器 - 总共增加40%宽度 */
        .content {
            width: 95%; /* 初始70% → 85% → 现在95% */
            max-width: 1300px; /* 初始900px → 1100px → 现在1300px */
            margin: 0 auto;
            padding: 40px;
            background-color: rgba(255, 255, 255, 0.15);
            backdrop-filter: blur(3px);
            border-radius: 8px;
        }

        /* 标题单独动画 */
        h1 {
            font-size: 2.8rem; /* 稍大字号 */
            margin-bottom: 2.5rem;
            color: #222;
            opacity: 0;
            transform: translateY(20px);
            animation: fadeInUp 1.2s ease-out forwards 0.5s;
            text-shadow: 0 0 10px rgba(255,255,255,0.6);
        }

        /* 正文容器 - 所有段落一起动画 */
        .text-body {
            opacity: 0;
            transform: translateY(15px);
            animation: fadeInUp 1.8s ease-out forwards 1s;
        }

        /* 段落样式 */
        p {
            font-size: 1.2rem; /* 稍大字号 */
            line-height: 1.9;
            margin-bottom: 1.8rem;
            color: #333;
            text-shadow: 0 0 6px rgba(255,255,255,0.4);
        }

        /* 更平滑的动画效果 */
        @keyframes fadeInUp {
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        /* 返回按钮 */
        .back-btn {
            position: fixed;
            top: 20px;
            left: 20px;
            padding: 10px 18px;
            background: rgba(255,255,255,0.85);
            color: #333;
            text-decoration: none;
            border-radius: 5px;
            font-weight: bold;
            font-size: 1.1rem;
            opacity: 0;
            animation: fadeIn 0.8s ease-out 2.5s forwards;
            transition: all 0.3s ease;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }

        .back-btn:hover {
            background: white;
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0,0,0,0.15);
        }

        @keyframes fadeIn {
            to { opacity: 1; }
        }
    </style>
</head>
<body>
    <a href="index.html" class="back-btn">← Back</a>
    
    <div class="content">
        <h1>Introduction: Good Image, Poor Image</h1>
        
        <div class="text-body">
            <p>My images are a form of fluid information, a medium of interaction and communication, and an important way of constructing identity and cognition.</p>
            <p>I use my phone to capture images. However, within the human-computer interaction interface, every seemingly simple action subtly submits me to the training of the machine (Manovich, 2020). I have realized that the algorithm is silently imposing its standards and influence on my images.</p>
            <p>The images I produce are, in fact, algorithmically processed versions—the algorithm undertakes editing and narration on my behalf, even without my authorization. For instance, when I take images—an unable to turn off function like Deep Fusion and High Dynamic Range.</p>
            <p>These features are embedded automatically, resulting in images that are algorithmic composites. When I press the shutter, the algorithm captures multiple images within a few seconds before and after the click.</p>
            <p>Every time I open my phone, I encounter algorithmically generated 'Memories'—images carefully selected from my album. These often include images of traveling, dining, spending time with family, friends, and pets—typically moments in which I am smiling.These are the images the algorithm identifies as 'good image'.</p>
        
        <p>My images are also categorized and defined by the system. This process of rendering individuals legible (Scott, 1999) essentially transforms the social relationships, identities, bodies, and behaviors embedded in the images into recognizable, exchangeable and manageable units—a mechanism saturated with control.</p>
        
        <p>I have always regarded my phone and my digital album as an extension to memory. Ideally, this would be a private domain. However, under algorithmic governance, it has become a heterotopia—a space where I can neither control nor intervene in the mechanisms of selection and recommendation.</p>
        
        <p>The algorithm imposes its own standards of what constitutes a 'good image' and a 'poor image'. Under this form of algorithmic violence, we are compelled to continually produce 'good image' while 'poor image' are modified, marginalized, and quietly hidden. They are denied equal visibility. Consequently, 'good image' are constantly reinforced before my eyes, while 'poor image' are neglected and forgotten.</p>
        
        <p>This has led me to question them, in such a highly detailed and standardized environment, individual photographs are technological, filtered, and categorized—and how these processes shape subjective aesthetic judgment.</p>
        
        <p>How are we 'compelled' to accept these standards? What constitutes a 'good image' or a 'poor image' in algorithmic terms? Where do these definitions converge or conflict with our personal aesthetics? And how might we resist this imbalance of power?</p>
        
        <p>In Defense of the Poor Image, Hito Steyerl (2008) argues that 'poor image' is low-resolution yet highly fluid, embodying a democratized replica of visuality. The essay was written a decade ago. Today, I believe the value of 'poor image' lies in their 'memories'—they are unoptimized, unsanitized, and untouched by algorithms. They represent an aesthetic marginalized by the prevailing machine standards, yet they testify to the subjectivity and diversity of human perception. They should not be indebted; we must always preserve space for 'poor image'.</p>
        
        <p>The gaze of the 'good image' surrounds us, circulating through the production and interaction of images. There is no safe distance from which to observe this already entrenched crisis—we are already immersed in it. We must reflect and we must respond.</p>
        
        <div class="citation">
            <p>Manovich, L. (2002) The Language of New Media. Cambridge, MA: MIT Press.</p>
            <p>Scott, J.C. (1999) Seeing Like a State: How Certain Schemes to Improve the Human Condition Have Failed. New Haven: Yale University Press.</p>
            <p>Steyerl, H. (2009) In defense of the poor image, e-flux journal, 10(11), pp. 1-6.</p>
        </div>
    </div>
</body>
</html>